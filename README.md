# LRU-Caches for Go

These are simple implementations of LRU cache, suitable both for study and
practical application:

- `ListCache` - classic implementation based on map and double-linked list
- `GensCache` - simpler and more compact, based on two maps (generations)

The latter allows to keep roughly twice more elements in the same amount
of memory as it uses two maps of the specified size - old and new generation.
Elements are added to new and when searched, both maps are checked (if the
element is found in the old it is promoted to new). When new reaches the
limit size it is reassigned as old, while old itself is discarded.

### Usage

Get the dependency, e.g.:

    go get github.com/rodiongork/lrucache

Now use it in your program, like this:

    package main

    import "github.com/rodiongork/lrucache"

    func main() {
        cache := lrucache.NewListCache[string, int](4)
        cache.Put("yksi", 1)
        cache.Put("kaksi", 2)
        cache.Put("kolme", 3)
        cache.Put("nelja", 4)
        cache.Put("viisi", 5)
        println(cache.Get("yksi"), cache.Get("viisi"))
    }

(it should print `0 5` as the first element was evicted already)

### Performance Study

Folder `study` holds small performance test which may be run with `go run test.go`
It shows the difference between two implementations:

    ListCache[50k]
	    hit: 4585k, miss: 15414k, time: 9.1
    GensCache[50k]
	    hit: 5477k, miss: 14522k, time: 6.7
    ListCache[100k]
	    hit: 6481k, miss: 13518k, time: 11.9
    GensCache[100k]
	    hit: 7658k, miss: 12341k, time: 7.4
    ListCache[250k]
	    hit: 10203k, miss: 9796k, time: 14.3
    GensCache[250k]
	    hit: 11743k, miss: 8256k, time: 9.3
    ListCache[500k]
	    hit: 14254k, miss: 5745k, time: 14.7
    GensCache[500k]
	    hit: 15711k, miss: 4288k, time: 10.6

The data consist of strings converted from six-digit decimal numbers which
are generated by randomizer (with the fixed seed) in non-uniform (rather cubic)
fashion.

It should be understood that real performance difference is observed when
misses lead to more slow data calculation / extraction (it doesn't happen in
this test for clarity of comparison).
